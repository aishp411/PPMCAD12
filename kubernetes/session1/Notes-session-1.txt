---------------------------
Kubernetes Training Program
---------------------------

Virtual Machine vs Container
----------------------------

Virtual Machine: 
- Hardware level virtualization - uses a Hypervisor (e.g: Microsoft Hyper-V, Oracle VirtualBox, VMware Workstation)
- Digital replica of a physical machine. Partitions the physical hardware into multiple environments
- Bootup time: minutes.

Container: 
- OS level virtualization - uses a Container Runtime (e.g: Dockerd, containerd, CRI-O, Podman)
- A software code package containing application code, libraries, and dependencies required to run the app.
- Bootup time: seconds.

Fact: Containers became popular in 2013 when Docker was introduced.

Biggest Difference Between VMs and Containers
---------------------------------------------

Virtual Machine Example
- Host machine: Windows OS
- Enable Hyper-V -> You can create Linux VMs on top of it

Container Example
- Host machine: Linux OS
- Can you create a Windows container on top of it? No.
- Containers must match the underlying host OS type.

Interview Question: How do you run Linux Containers on Windows Laptop using Docker Desktop?
-------------------------------------------------------------------------------------------

There are 2 options but in both of them, Docker Desktop runs a Linux OS in the background to run the Linux Docker container on it:

- Option 1: Docker Desktop uses Hyper-V to provision a Linux VM in the background. Linux containers run inside this VM.
- Option 2: Docker Desktop can also integrate natively with WSL2, which runs a lightweight Linux kernel in the background.


Additional Question discussed during the session:
------------------------------------------------

1.) Developer Use Cases

Case 1: Developer/DevOps with Windows Laptop
  Needs to test or work with Linux containers.
  Install Docker Desktop with WSL2 -> allows seamless Linux container usage.

Case 2: Developer/DevOps with Linux Laptop (rare, <1%)
  Needs to test or work with Windows containers.
  Requires provisioning Windows VMs/servers.


2.) Production Deployment Scenarios
------------------------------------

Linux Containers: Always run on Linux VMs/servers.

Windows Containers: Always run on Windows VMs/servers.


Most Important Benefit of running Containers
---------------------------------------------

Package your executable code with dependencies, runtime, and OS libraries -> portable across any environment.

Expanded view:
- Consistency Across Environments:
  - Traditionally, applications often worked on a developer's laptop but failed in testing or production because of missing libraries, different OS versions, or conflicting dependencies ("It works on my machine" problem).

  - Containers eliminate this by packaging the entire runtime environment (app code + dependencies + binaries + system tools + OS libraries) inside the container image.

  - No matter where you run it (developer laptop, CI/CD pipeline, on-prem server, or cloud provider), the application behaves the same.

- Portability:
  - A container image is generally lightweight excluding a few windows containers, standardized, and can run anywhere there's a container runtime (Docker, containerd, CRI-O).

  - This makes applications cloud-agnostic -> the same image runs on AWS, Azure, GCP, or on bare-metal servers.


-------------
Session 1:
-------------


The Shipping Analogy:
---------------------

Traditional Shipping (Before Containers):
Different sized boxes, crates, barrels
Complex loading/unloading
Different handling methods for each item
Inefficient space usage
More labor intensive

Modern Shipping Containers:
Standardized container size
Same handling equipment everywhere
Works on any ship/truck/train
Efficient loading/unloading
Easy to track and manage

Software Parallel:
Traditional Apps = Like old shipping (each needs special handling)
Containerized Apps = Like modern containers (standardized, runs anywhere)

Kubernetes = Modern automated port that:
Manages thousands of containers
Routes traffic efficiently
Adds/removes containers as needed
Automatically handles failures
Distributes load across servers

Just like modern ports need automation to handle thousands of containers efficiently, Kubernetes automates container management at scale



Kubernetes Use Cases discussed during the session:
---------------------------------------------------

1.) Scaling Scenario (e.g., An App running in Production on Kubernetes):
  - Kubernetes Cluster setup: 1 Control Plane + 3 Worker Nodes.
  - Initially: 10 containers running, Kubernetes based auto-scaling enabled.
  - Traffic spike
    - How Kubernetes Responds:
      - The container (Pods in Kubernetes env) will scale to 20 using its native Horizontal Pod Auto-scalar (still on 3 worker nodes).
  - The traffic still increasing but the Worker nodes max out CPU/memory whereas we need 40 containers.
    - How Kubernetes responds:
        - On AWS/EKS: Auto-scaling group provisions new worker nodes automatically.
        - On self-managed cluster: Admin manually adds worker nodes.

2.) Resource-heavy container scenario:

  - App requests 8 CPU & 32 GB RAM.
  - Worker node only has 4 CPU & 16 GB RAM -> Pod cannot be scheduled.


Microservices World & Service Discovery in Kubernetes:
------------------------------------------------------

Example Flow of different microservices in an ecommerce website talking to each other:

- Service Catalog Microservice -> Checkout Microservice -> Payments Microservice
- All microservices run inside Kubernetes Pods
- Service discovery via Kubernetes Core DNS (which is an internal service and runs inside each Kubernetes Cluster) + Kubernetes Services (Kubernetes native object) ensures microservices can talk to each other reliably, without hardcoding IPs.

Other Microservices examples which leverages Kubernetes Service Discovery:
  E-commerce: User Service -> Cart Service -> Payment Service -> Notification Service
  Streaming: User Profile -> Recommendation -> Streaming -> Billing
  Banking: Account -> Transaction -> Fraud Detection -> Notification


Pod and Containers:
-------------------

  - Pod = smallest unit in Kubernetes.
  - Pod spec includes: container image (name, registry, tag).
  - Pods usually run 1 main container + supporting (sidecar) containers.

Examples of supporting containers:
  
  - Log collector -> ships logs to central system.
  - Redis cache -> supports main app.
  - Metrics exporter -> exposes monitoring data.


How does Kubernetes cluster components Work Together:
-----------------------------------------------------

- User/Admins interacts with the cluster through the API server
- API server validates and processes the request
- Scheduler assigns Pods to Nodes
- Controller manager ensures desired state is maintained
- kubelet communicates with the API server and manages containers on the node
- kube-proxy manages network communication for Pods
- etcd saves the current state of the cluster


Hands-on Lab: 
-------------


1.) Minikube:
-------------

Minikube: Minikube is a tool that lets you run Kubernetes locally, creating a single-node cluster on your machine.

Installation Steps: installation-guides\Minikube-Installation-Windows.txt

Task: 
    a.) Run: `kubectl get pods -A`
        Explain the meaning of this command
        Explain the usage of all the pods in the output of the above command


2.) Navigating the Kubernetes CLI (kubectl) commands:
-----------------------------------------------------

kubectl is the command-line tool for interacting with Kubernetes clusters.

Common commands with examples:
a.) kubectl get: List resources
e.g.: kubectl get pods -A

b.) kubectl describe: Show detailed information about a resource
e.g.: kubectl describe pod coredns-6f6b679f8f-vph5r -n kube-system

c.) kubectl create: Create a resource 
e.g.: kubectl create deployment nginx --image=<ecr-endpoint>/nginx:<tag>

d.) kubectl apply: Apply a configuration to a resource
e.g.: kubectl apply -f manifests\demo-deployment.yaml

e.) kubectl delete: Delete resources
e.g.: kubectl delete deployment nginx


3.) Kubeconfig:
---------------

A file that is used to configure access to the Kubernetes clusters is called a kubeconfig file.

Check the C:\Users\<username>\.kube\config file in your Windows Laptop

Reference: sample-kubeconfig\kubeconfig

Key components:
a.) Clusters: Defines the Minikube cluster, including the server address and the path to the certificate authority.
b.) Contexts: Specifies how to connect to the cluster, including which user to use and which namespace to use by default.
c.) current-context: Indicates which context is currently active (in this case, "minikube").
d.) users: Contains authentication information for connecting to the cluster.

Managing contexts:
a.) View contexts: kubectl config get-contexts
b.) Switch contexts: kubectl config use-context minikube



4.) understanding the YAML files:
---------------------------------

YAML Files:

  A - API version: Specifies which version of the Kubernetes API you're using
      Examples: v1, apps/v1, networking.k8s.io/v1
  K - Kind: Defines what type of Kubernetes resource you're creating
      Examples: Pod, Deployment, Service, ConfigMap, etc.
  M - Metadata: Contains data that helps identify the object
      name: unique name for the resource
      labels: key-value pairs for organizing resources
      namespace: the namespace where resource will be created
      annotations: additional information about the resource
  S - Specs: Defines the desired state of the resource
      Contains all the configuration specific to the Kind
      Structure varies based on the Kind of resource
      Most detailed section of the YAML

e.g:

apiVersion: v1
kind: Pod
metadata:
  name: pod
  labels:
    app: app
  namespace: default
spec:
  containers:
  - name: myapp-container
    image: busybox
    command: ['sh', '-c', 'echo Hello Kubernetes! && sleep 3600']



5.) Deploy a sample app on Minikube and access the endpoint:
------------------------------------------------------------

kubectl apply -f manifests\demo-deployment.yaml
kubectl apply -f manifests\demo-svc.yaml
kubectl apply -f manifests\demo-svc-np.yaml

To test, open the port (node port specified in the service yaml) in your windows laptop via firewall
command: New-NetFirewallRule -DisplayName "Open Port <node-port>" -Direction Inbound -LocalPort <node-port> -Protocol TCP -Action Allow


Get Minikube Control Plane IP by running: "minikube ip" command
Browse the Nginx Homepage: http://<Minikube-control-plane-ip>:<node-port>

Cleanup the deployment:

kubectl delete -f manifests\demo-deployment.yaml
kubectl delete -f manifests\demo-svc.yaml
kubectl delete -f manifests\demo-svc-np.yaml

Explore before the next session:
--------------------------------

1.) How does DNS record gets resolved: e.g: How does the domain name https://kubernetes.io will get resolved in your browser
2.) Try to containerize an application by yourself, a simple java / python / nodejs program.
3.) What are containers, and why their adaptability is very high?
4.) Install Minikube and run all the manifest files share along with this notes
5.) Explore Kubernetes Dashboard via minikube
6.) Explore Kubernetes Imperative vs Declarative commands


------------------------

Anything which we run inside K8S cluster, 

1 Control plane (static ip) - 2 worker nodes (static ips), 13.26.27.146:30080

inside a VPC (That it should a public subnet - igw in its route table)

I need to access the nginx from outside:

Kubernetes Service:

ClusterIP - This is what gives a static identity to pods in k8s
NodePort - It will pick a port from range between 30000 - 32000, 30080 
Load Balancer - It will create a LoadBalancer inside CloudProvider, it will create a NLB/ CLB inside AWS, Layer 4 Load Balancer inside Azure

Ingress - 


Node -> Deployment -> 5 Pods

1 Service -> 5 Pods 