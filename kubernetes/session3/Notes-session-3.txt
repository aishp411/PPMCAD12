---------------------------
Kubernetes Training Program
---------------------------

-------------
Session 3:
-------------


Detailed view into Kubernetes Objects:
--------------------------------------

Understand Pods:
----------------

Pods: Pods are the smallest deployable units in Kubernetes. A pod is scheduled on the one node, ensuring co-location of containers.

Key features:
- A pod can contain one or more containers
- Containers within a pod share the same network namespace and can communicate via localhost
- Ephemeral in nature, and can be created, destroyed, and recreated dynamically.

Pod Lifecycle: Pods have a defined lifecycle with states like Pending, Running, Succeeded, Failed, and Unknown.

handson:
- Get Pods status
- Describe Pods // kubectl describe pod aws-node-5z5hq -n kube-system
- Check the logs // kubectl logs aws-load-balancer-controller-6cb4b5dc7f-fwcwm -n kube-system
- Delete the pod // kubectl delete pod <pod-name> -n <namespace> // kubectl delete -f <yaml-file-path-name>.yaml
- check the pod manifest
- understand the init containers and multi-container / sidecar container use case
    - sample: manifests\multi-container-pod-demo.yaml
- Logs of a container: kubectl logs multi-container-example -c log-sidecar

Understanding the Kubernetes ReplicaSet & Deployment Object:
------------------------------------------------------------

ReplicaSets: ReplicaSets ensure that a specified number of pod replicas are running at any given time.

Key features:
- Maintains a stable set of replica Pods
- Ensures high availability
- Allows easy scaling of applications


Deployments: Deployments provide declarative updates for Pods and ReplicaSets.

Key features:
- Describe desired state
- Control the rate of change to Pods // release new changes to an application without any downtime
- Provide rollback functionality


Deployment -> ReplicaSet -> Pod/s

Why deployment over replicasets:

- Deployments provide built-in support for rolling updates and easy rollbacks
- Deployments maintain a revision history, allowing you to roll back to previous versions
- Deployments offer configurable update strategies like RollingUpdate and Recreate
- Deployments act as a higher-level abstraction, managing ReplicaSets behind the scenes


handson:
- check the deployment manifest
    - sample: manifests\pcatalog-deployment-demo.yaml
- deploy this
- Get deployment status // kubectl get deployment -n default
- Describe deployment
- Check the logs
- check the replicasets created from the deployment Object
- check the pods created from the replicaset object
- manually scale the deployment // kubectl scale deployment product-catalog-demo --replicas=5
- update the deployment with the latest application version // change the image from nginx to httpd
- rollback the deployment to the older version // kubectl rollout undo deployment/product-catalog
- delete the deployment
- Check rollout history // kubectl rollout history deployment/<deployment_name> -n <namespace>

Understanding the Kubernetes Service Object:
--------------------------------------------

Services provide network access to a set of Pods.

Types of Services:
a.) ClusterIP: Exposes the service on an internal IP in the cluster
 5 nginx pods -> all of them having separate ephemeral IPs

 I create a ClusterIp service -> Point this service to 5 Pods via labels and selectors

 and now I get a fixed identity

 the service will have 2 attributes: 1.) Static Private IP (which will never change) 2.) Static Domain name for my pods running inside Kubernetes

 It is meant for service to communicate with each other

The end user is only accessing the frontend service:

 frontend service (externally available) -> backend service -> database service (assuming db is running inside k8s)

b.) NodePort (used for lower env dev/test): Exposes the service on each Worker Node's IP at a static port, but generally used in Non-prod scenarios, the range of nodeport: 30000 - 32767

54.179.26.128:30080 / 172.31.29.60:30080 / 54.151.189.127:30080


c.) LoadBalancer: Exposes the service externally using a cloud provider's load balancer

Key features:
Services provide a stable IP address and DNS name for a set of Pods
Enables seamless service discovery and load balancing within the cluster
Abstract the underlying Pod network, allowing applications to communicate without knowing the exact Pod IPs, which can change frequently.

handson:
- check the following service manifest
    - sample: manifests\pcatalog-service-cip-demo.yaml
    - sample: manifests\pcatalog-service-np-demo.yaml
    - sample: manifests\pcatalog-service-lb-demo.yaml
- Deploy the services
- Get service status
- Describe service
- Check the logs

Think of a scenario:

wherein we are hosting a microservices based app:

it has following microservices:

frontend  <-> LoadBalancer 
admin     <-> LoadBalancer
api       <-> LoadBalancer
backend   - clusterIP
database  - clusterIP

https://demo.com
----

Ingress: Will create 1 LoadBalancer and then it will start forwarding the requests to different services:

Route53 (DNS Service of AWS) : Record for demo.com pointing to the NLB created by Ingress

The NLB will forward the traffic to internal ingress controller

https://demo.com -> frontend service -> backend service -> database service 
https://demo.com/admin -> admin service -> backend service -> database service 
https://demo.com/api -> api service -> backend service -> database service 




Check the ClusterIp service by getting inside a container in the same namespace:
e.g.: 
- kubectl exec -it running-pod -- bash

Understanding the Kubernetes ConfigMaps & Secrets Object:
---------------------------------------------------------

ConfigMaps allow us to decouple configuration artifacts from image content.

Key features:
- Store non-sensitive configuration data as key-value pairs or files.
- Can be mounted as volumes or used as environment variables in Pods.

Secrets are used to store and manage sensitive information.

Key features:
- Secrets are stored in a base64 encoded format
- Store sensitive information (e.g., passwords, tokens) with encryption at rest in etcd.
- Can be mounted as volumes or used as environment variables in Pods, similar to ConfigMaps, but with additional security measures.

kubec@kubec:~$ echo "very-secret-password" | base64
dmVyeS1zZWNyZXQtcGFzc3dvcmQK
kubec@kubec:~$
kubec@kubec:~$ echo "dmVyeS1zZWNyZXQtcGFzc3dvcmQK" | base64 -d
very-secret-password


handson:
- check the manifest files
    - sample: manifests\pcatalog-cm-demo.yaml
    - sample: manifests\pcatalog-secret-string-data-demo.yaml
    - sample: manifests\pcatalog-secret-data-demo.yaml
- Apply them
- Check their accessibility in the Pods which are created via the deployment



Understanding the Kubernetes Horizontal Pod Autoscaling:
---------------------------------------------------------

Pre-requisite: Deployment of Metrics server is required for HPA to function. Metrics server helps to analyze Node and Pod Level CPU and Memory status.
    - Steps to install metrics server: metrics-server\Installation-Guide.txt
    - Run below command to get the pods and nodes metrics:
        kubectl top pods -A
        kubectl top node


HPA automatically scales the number of pods in a deployment or StatefulSet based on observed CPU utilization or memory utilization or any other custom metrics.

Key features:
- Supports both resource-based (CPU/memory) and custom/external metrics for scaling decisions.
- Allows setting of minimum and maximum number of replicas

handson:
- Apply the deployment and the service manifests:
    - manifests\pcatalog-deployment-demo.yaml
    - manifests\pcatalog-service-demo.yaml
- check the manifest files
    - sample: manifests\pcatalog-hpa-demo.yaml
- Apply it
- Watch the HPA from 1st terminal // kubectl get hpa product-catalog-hpa-demo -w
- Watch the pods from 2nd terminal // kubectl get pods -l app=product-catalog -w
- Generate load from 3rd terminal
    - First, get the service IP
        - kubectl get service product-catalog-service -o jsonpath='{.spec.clusterIP}'
    - Exec into any pod and then run a loop to send requests and increase CPU load:
        - kubectl get pods
        - kubectl exec -it <po-name-from-above> -- bash
        - Run:
            while true; do curl -s -o /dev/null -w "%{http_code}" http://<SERVICE_IP_OBTAINED_ABOVE>;done

            while true; do curl -s -o /dev/null -w "%{http_code}" http://product-catalog-cip-service;done
- Switch between different terminals to see the CPU percentage increasing and subsequent scaling of Pods
- Stop the curl command in the 3rd terminal to stop the load
- Again check the CPU percentage and the pods getting scaled back down
- Delete HPA


Namespace:
----------

Namespaces in Kubernetes are a way to divide cluster resources between multiple users, projects or environments. They help to organize and isolate resources within a cluster.


Key features:
Namespaces allow you to create multiple virtual clusters within the same physical cluster for multi-tenant environments
Implement resource quotas and limit resource usage per namespace.
Enables to work with multiple environments within a cluster (dev, test, prod)
Access control across multiple teams

Default Namespaces: Kubernetes starts with four initial namespaces:
default: For resources with no other namespace
kube-system: For objects created by or for the Kubernetes system
kube-public: Created automatically and readable by all users
kube-node-lease: Special namespace that plays a crucial role in the node heartbeat mechanism to control plane

handson:
- Create namespace // kubectl create ns hvd or kubectl apply -f manifests\namespace-demo.yaml
- Setting the Namespace Preference // kubectl config set-context --current --namespace=kube-system
- View existing namespaces // kubectl get ns
- Describe namespace // kubectl describe ns hvd
- Viewing Resources in a Namespace // kubectl get pods --namespace=hvd or kubectl get pods -n hvd
- Deleting a namespace (Run with responsibility) // kubectl delete ns hvd


Important Info:

Some Namespace scoped objects: Pods, ReplicaSets, Deployments, Services, ConfigMaps, Secrets, Ingresses, StatefulSets, DaemonSets, HorizontalPodAutoscalers, PersistentVolumeClaims etc.

Some cluster Scoped Kubernetes Objects: Nodes, PersistentVolumes, StorageClasses, CSIDrivers etc.

DaemonSets:
-----------

It calculates - the total worker nodes

kubectl get nodes 

Monitoring - Monitoring agents - I  need to run it on all my worker 

Logging agent

DaemonSet ensures that all nodes run a copy of a Pod by respecting the node placement strategies.

As nodes are added/removed from the cluster, Pods are added/removed from those nodes automatically.

Key features:
One Pod per Node
Automatic Pod Management
Bypasses Scheduler's Node Selection
Respect all node placement strategies
Updates can be Rolling or OnDelete

Common Use Cases:
Monitoring Agents (Prometheus Node Exporter)
Log Collectors (Fluentd, logstash)
Networking Plugins (aws vpc cni)
Storage Plugins (EBS CSI Driver)

handson:
- Apply daemonsets as per the below sample:
    - kubectl apply -f manifests\daemonsets-demo.yaml
